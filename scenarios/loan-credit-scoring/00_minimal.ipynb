{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf379459",
   "metadata": {},
   "source": [
    "# \ud83c\udfaf Level 0: The \"Aha!\" Moment - Credit Scoring\n",
    "\n",
    "**\u23f1\ufe0f Time**: < 60 seconds  \n",
    "**\ud83c\udf93 Complexity**: \u2b50 Beginner  \n",
    "**\ud83c\udfaf Goal**: See your first governance audit with minimal code\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda What You'll Learn\n",
    "\n",
    "- How to run a governance policy on raw data\n",
    "- What a compliance report looks like\n",
    "- Why data audits matter **before** model training\n",
    "\n",
    "\ud83d\udca1 **No model training needed!** Just data + policy = instant compliance check\n",
    "\n",
    "This notebook shows how **OSCAL-native governance** (Open Security Controls Assessment Language) makes compliance auditable and version-controlled\u2014just like your code.\n",
    "\n",
    "### \ud83c\udf93 Why This Matters (The Real-World Context)\n",
    "\n",
    "- **Trust**: Transparent audits help stakeholders understand your system's behavior\n",
    "\n",
    "**Credit scoring models affect people's lives.** A rejected loan application can prevent someone from buying a home, starting a business, or handling an emergency. Historically, ML systems have replicated discriminatory patterns from biased historical data (e.g., redlining, gender discrimination in lending).- **Regulatory compliance**: Many jurisdictions (EU AI Act, US Fair Lending laws) require fairness checks\n",
    "\n",
    "- **Cheaper to fix**: Data issues are easier to address than retrained models\n",
    "**Governance-first approach:** By auditing data *before* training, you catch bias early:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebf783",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Load Data\n",
    "\n",
    "First, let's import what we need and load the German Credit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Credit Scoring: The Aha! Moment\n",
      "\n",
      "\u2705 Loaded 1000 loan applications from local file\n",
      "   Columns: checking_status, duration, credit_history, purpose, credit_amount...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status_sex</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "      <th>target</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>...</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>...</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration credit_history purpose  credit_amount  \\\n",
       "0             A11         6            A34     A43           1169   \n",
       "1             A12        48            A32     A43           5951   \n",
       "2             A14        12            A34     A46           2096   \n",
       "3             A11        42            A32     A42           7882   \n",
       "4             A11        24            A33     A40           4870   \n",
       "\n",
       "  savings_status employment  installment_commitment personal_status_sex  \\\n",
       "0            A65        A75                       4                 A93   \n",
       "1            A61        A73                       2                 A92   \n",
       "2            A61        A74                       2                 A93   \n",
       "3            A61        A74                       2                 A93   \n",
       "4            A61        A73                       3                 A93   \n",
       "\n",
       "  other_parties  ...  other_payment_plans housing  existing_credits   job  \\\n",
       "0          A101  ...                 A143    A152                 2  A173   \n",
       "1          A101  ...                 A143    A152                 1  A173   \n",
       "2          A101  ...                 A143    A152                 1  A172   \n",
       "3          A103  ...                 A143    A153                 1  A173   \n",
       "4          A101  ...                 A143    A153                 2  A173   \n",
       "\n",
       "  num_dependents  own_telephone foreign_worker  class target  gender  \n",
       "0              1           A192           A201      1      1    male  \n",
       "1              1           A191           A201      2      0  female  \n",
       "2              2           A191           A201      1      1    male  \n",
       "3              2           A191           A201      1      1    male  \n",
       "4              2           A191           A201      2      0    male  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import venturalitica as vl\n",
    "\n",
    "print(\"\ud83d\ude80 Credit Scoring: The Aha! Moment\\n\")\n",
    "\n",
    "# Load the German Credit dataset (1,000 real loans)\n",
    "data_path = Path(\"data/german_credit.csv\")\n",
    "\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"\u274c Dataset not found. Please run: uv run prepare_data.py\\n\"\n",
    "        f\"   Expected location: {data_path}\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"\u2705 Loaded {len(df)} loan applications from local file\")\n",
    "\n",
    "# Basic cleanup to ensure governance columns are present\n",
    "df['age'] = pd.to_numeric(df.get('age'), errors='coerce')\n",
    "df = df.dropna(subset=['age'])\n",
    "df['target'] = pd.to_numeric(df.get('target'), errors='coerce').astype('int64')\n",
    "if 'gender' not in df.columns:\n",
    "    df['gender'] = 'unknown'\n",
    "\n",
    "print(f\"   Columns: {', '.join(df.columns[:5])}...\")\n",
    "\n",
    "# Display first few rows for a quick sanity check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6defe",
   "metadata": {},
   "source": [
    "### Why this data matters\n",
    "\n",
    "**Dataset**: German Credit (UCI ML Repository, 1,000 real loan applications from 1994)\n",
    "- **Historical context**: One of the earliest fairness benchmarks in ML; frequently used to study discrimination in lending.\n",
    "\n",
    "- **Protected attributes**: `gender`, `age`, `foreign_worker` status\u2014attributes where discrimination is illegal in most jurisdictions.\ud83d\udca1 **Pro tip**: In production, you'd version-control both the dataset *and* the policy file so audits are reproducible.\n",
    "\n",
    "- **Target**: `target=1` means \"creditworthy\" (approved loan); `target=0` means \"not creditworthy\" (rejected).\n",
    "\n",
    "**Why minimal cleaning?** Real governance audits often happen on raw data to catch issues before expensive transformations. Here we only ensure required columns exist and are numeric so the policy can compute fairness metrics.\n",
    "\n",
    "**Critical columns for governance**:\n",
    "\n",
    "- `target`: The decision we're auditing (loan approval)- `age`: Another protected attribute; some regulations require age-group fairness\n",
    "- `gender`: Protected attribute (male/female); policies check demographic parity here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e0adce",
   "metadata": {},
   "source": [
    "## Step 2: Point to a Governance Policy\n",
    "\n",
    "The policy defines what \"fair\" and \"compliant\" means for this scenario.\n",
    "\n",
    "Think of it as \"unit tests for fairness\"\u2014automated checks that run every time your data or model changes.\n",
    "\n",
    "### \ud83c\udf93 What is OSCAL?\n",
    "\n",
    "**OSCAL (Open Security Controls Assessment Language)** is a NIST standard for machine-readable compliance documentation. Originally designed for cybersecurity, it's perfect for ML governance because:- **Interoperable**: Can be validated by external auditors or regulators\n",
    "\n",
    "- **Version-controlled**: Policies live in Git alongside your code- **Auditable**: Each control has a unique ID, description, and threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Using policy: policies/loan/risks.oscal.yaml\n",
      "   This policy checks:\n",
      "   \u2022 Demographic parity (gender fairness)\n",
      "   \u2022 Data quality (class balance)\n",
      "   \u2022 Accuracy calibration\n"
     ]
    }
   ],
   "source": [
    "policy_path = Path(\"policies/loan/data_policy.oscal.yaml\")\n",
    "print(f\"\u2705 Using policy: {policy_path}\")\n",
    "print(f\"\\n\ud83d\udccb This policy checks:\")\n",
    "print(f\"   \u2022 Demographic parity (gender fairness)\")\n",
    "print(f\"       \u2192 Equal approval rates across genders (within tolerance)\")\n",
    "print(f\"   \u2022 Data quality (class balance)\")\n",
    "\n",
    "print(f\"       \u2192 Sufficient representation of both classes (approved/rejected)\")\n",
    "print(f\"\\n\ud83d\udca1 Each check is a 'control' with a threshold. Fail = investigate & fix.\")\n",
    "\n",
    "print(f\"   \u2022 Accuracy calibration\")print(f\"       \u2192 Model predictions should match true positive rates across groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950b324",
   "metadata": {},
   "source": [
    "## Step 3: Run the Audit \ud83d\udee1\ufe0f\n",
    "\n",
    "This is where the magic happens! No model needed - just data + policy.\n",
    "\n",
    "**Why this is powerful**: Same `enforce()` call works pre-training (data audit), post-training (model audit), and in production (monitoring). You write the policy once; it runs everywhere.\n",
    "\n",
    "### \ud83c\udf93 What `vl.enforce()` Does Under the Hood\n",
    "\n",
    "4. **Returns structured results**: Pass/fail status, actual values, human-readable messages\n",
    "\n",
    "1. **Parses the OSCAL policy** to extract control definitions (thresholds, metrics, protected attributes)3. **Evaluates each control**: Compare actual metric values against policy thresholds\n",
    "\n",
    "2. **Computes fairness metrics** from your data:   - Representation: Sample sizes per protected group\n",
    "\n",
    "   - Demographic parity: $P(\\hat{y}=1 | \\text{male}) \\approx P(\\hat{y}=1 | \\text{female})$   - Class balance: $\\frac{\\text{min}(n_{pos}, n_{neg})}{\\text{total}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56277f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udee1\ufe0f  Running data quality audit...\n",
      "\n",
      "\n",
      "[Venturalitica] \ud83d\udee1  Enforcing policy: policies/loan/risks.oscal.yaml\n",
      "  Evaluating Control 'credit-data-imbalance': Data Quality: Minority class (rejected loans) shou...\n",
      "    [Binding] Virtual Role 'target' bound to Variable 'target' (Column: 'target')\n",
      "  Evaluating Control 'credit-data-bias': Pre-training Fairness: Disparate impact ratio shou...\n",
      "    [Binding] Virtual Role 'target' bound to Variable 'target' (Column: 'target')\n",
      "    [Binding] Virtual Role 'dimension' bound to Variable 'gender' (Column: 'gender')\n",
      "  Evaluating Control 'credit-age-disparate': Disparate impact ratio for raw age (Proxy for seni...\n",
      "    [Binding] Virtual Role 'target' bound to Variable 'target' (Column: 'target')\n",
      "    [Binding] Virtual Role 'dimension' bound to Variable 'age' (Column: 'age')\n",
      "  \u274c FAIL | Controls: 2/3 passed\n",
      "    \u2713 [credit-data-imbalance] Data Quality: Minority class (rejected l...: 0.429 (Limit: gt0.2)\n",
      "    \u2713 [credit-data-bias] Pre-training Fairness: Disparate impact ...: 0.897 (Limit: gt0.8)\n",
      "    \u2717 [credit-age-disparate] Disparate impact ratio for raw age (Prox...: 0.286 (Limit: gt0.5)\n",
      "  \u2713 Results cached for 'venturalitica push'\n",
      "\n",
      "\u2705 Audit complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\ud83d\udee1\ufe0f  Running data quality audit...\\n\")\n",
    "\n",
    "# Run the audit - this is the core venturalitica.enforce() call\n",
    "results = vl.enforce(\n",
    "    data=df,\n",
    "    target='target',      # The approval decision column\n",
    "    gender='gender',      # The protected attribute\n",
    "    policy=str(policy_path)\n",
    ")\n",
    "\n",
    "print(\"\\n\u2705 Audit complete!\")\n",
    "print(f\"\ud83d\udcca Evaluated {len(list(results.values() if isinstance(results, dict) else results))} controls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2dde07",
   "metadata": {},
   "source": [
    "## Step 4: Visualize Results \ud83d\udcca\n",
    "\n",
    "Let's see what the audit found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851e2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GOVERNANCE AUDIT RESULTS\n",
      "============================================================\n",
      "\n",
      "\u2705 PASSED | credit-data-imbalance\n",
      "   Description: Data Quality: Minority class (rejected loans) should represent at least 20% of the dataset to avoid biased training due to severe Class Imbalance.\n",
      "   Value: 0.42857142857142855\n",
      "\n",
      "\u2705 PASSED | credit-data-bias\n",
      "   Description: Pre-training Fairness: Disparate impact ratio should follow the standard '80% Rule' (Four-Fifths Rule), ensuring favorable loan outcomes are representative across groups.\n",
      "   Value: 0.8965673282047968\n",
      "\n",
      "\u274c FAILED | credit-age-disparate\n",
      "   Description: Disparate impact ratio for raw age (Proxy for seniority)\n",
      "   Value: 0.2857142857142857\n",
      "\n",
      "============================================================\n",
      "SUMMARY: 2/3 controls passed\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GOVERNANCE AUDIT RESULTS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "raw_results = results.values() if isinstance(results, dict) else results\n",
    "result_list = list(raw_results)\n",
    "\n",
    "for r in result_list:\n",
    "    status = \"\u2705 PASSED\" if getattr(r, 'passed', False) else \"\u274c FAILED\"\n",
    "    control_id = getattr(r, 'control_id', 'unknown_control')\n",
    "    description = getattr(r, 'description', '')\n",
    "    message = getattr(r, 'message', '') or getattr(r, 'details', '')\n",
    "    print(f\"{status} | {control_id}\")\n",
    "    if description:\n",
    "        print(f\"   Description: {description}\")\n",
    "    if not getattr(r, 'passed', False) and message:\n",
    "        print(f\"   \u26a0\ufe0f  Issue: {message}\")\n",
    "    actual_value = getattr(r, 'actual_value', None)\n",
    "    if actual_value is not None:\n",
    "        print(f\"   Value: {actual_value}\")\n",
    "    print()\n",
    "\n",
    "# Summary\n",
    "passed = sum(1 for r in result_list if getattr(r, 'passed', False))\n",
    "total = len(result_list)\n",
    "print(\"=\"*60)\n",
    "print(f\"SUMMARY: {passed}/{total} controls passed\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd436330",
   "metadata": {},
   "source": [
    "### How to read the report\n",
    "- **PASSED** controls: data satisfies the policy requirement.\n",
    "- **FAILED** controls: investigate the message to fix data quality/fairness issues.\n",
    "- Rerun after fixing data to see compliance improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d4981",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 That's it!\n",
    "\n",
    "You just completed your first governance audit with Venturalitica in less than 60 seconds.\n",
    "\n",
    "### What happened?\n",
    "- \u2705 The SDK validated your data against a **real OSCAL-native policy**\n",
    "- \u2705 It checked for data quality, fairness, and bias requirements\n",
    "- \u2705 You got actionable results you can show to compliance teams\n",
    "\n",
    "### Next Steps\n",
    "Want to see more? Check out:\n",
    "- `01_governance_audit.ipynb` - Full ML training pipeline with pre/post-training audits\n",
    "- `02_mlops_integration.py` - Integration with MLflow experiment tracking\n",
    "- `03_production_ready.py` - Production-grade governance workflows\n",
    "\n",
    "**Ready to build compliant AI systems? Let's go! \ud83d\ude80**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd184d9",
   "metadata": {},
   "source": [
    "### How to read these metrics\n",
    "- **Status / passed controls**: shows whether each policy control is satisfied. `passed` counts how many controls cleared; `total` is the number evaluated.\n",
    "- **actual_value**: the measured value for the control (for example, a threshold or rate the policy checks).\n",
    "- **message / description**: human-readable summary of why a control passed or failed.\n",
    "- **source_note**: provenance of the data used for the check so you can trace the evidence.\n",
    "\n",
    "If a control fails, start with its `message` to see which data field or rule triggered the issue, then look at `actual_value` to understand by how much it deviated from the policy expectation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venturalitica-integration (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}