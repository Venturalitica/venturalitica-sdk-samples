{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# \ud83c\udfaf Level 2: The Integrator - MLOps & Metadata\n",
    "\n",
    "**\u23f1\ufe0f Time**: 3 minutes  \n",
    "**\ud83c\udf93 Complexity**: \ud83d\udfe1 Intermediate  \n",
    "**\ud83c\udfaf Goal**: Automate the audit check inside a training pipeline (MLOps).\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda What You'll Learn\n",
    "\n",
    "- How to simulate a training run\n",
    "- How to use `vl.monitor()` for Green AI & Hardware tracking\n",
    "- How to implement the **Two-Policy Handshake** (Data vs. Model)\n",
    "\n",
    "\ud83d\udca1 **Focus**: Compliance is just another metric, like Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import venturalitica as vl\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\ud83d\ude80 Loan Scenario: The Integrator\")\n",
    "print(\"\ud83d\udfe2 Starting MLOps Simulation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training",
   "metadata": {},
   "source": [
    "## Step 1: The 'Green AI' Monitor & Data Audit\n",
    "\n",
    "Before we train, we turn on the `monitor`. This captures hardware usage.\n",
    "We also perform the **Article 10** pre-training audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Zero-Config Monitor\n",
    "with vl.monitor(\"xgboost_training_run\"):\n",
    "    # 1.1 Data Audit (Article 10)\n",
    "    # We ensure the data is fair BEFORE training\n",
    "    try:\n",
    "        df = vl.load_sample(\"loan\")\n",
    "        vl.enforce(\n",
    "            data=df,\n",
    "            target=\"target\",\n",
    "            policy=\"policies/loan/data_policy.oscal.yaml\"\n",
    "        )\n",
    "        print(\"   \u2713 Data Audit Passed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   \u26a0\ufe0f Data Audit Warning: {e}\")\n",
    "\n",
    "    # 1.2 Stimulate Training\n",
    "    print(\"   \u2699\ufe0f Training model... (Simulating Load)\")\n",
    "    time.sleep(2)  # Pretend we are training hard\n",
    "    print(\"   \u2705 Model Trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "audit_check",
   "metadata": {},
   "source": [
    "## Step 2: The 'Model Behavior' Audit\n",
    "\n",
    "Now we audit the **Output** of the model (Article 15).\n",
    "Notice the shift: `target='prediction'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Post-Training Audit\n",
    "try:\n",
    "    # Prepare mock predictions\n",
    "    df = vl.load_sample(\"loan\")\n",
    "    df['prediction'] = df['target'] # Perfect model for simulation\n",
    "    \n",
    "    results = vl.enforce(\n",
    "        data=df,\n",
    "        target=\"target\",\n",
    "        prediction=\"prediction\",\n",
    "        gender=\"gender\",\n",
    "        policy=\"policies/loan/model_policy.oscal.yaml\"\n",
    "    )\n",
    "    print(\"\u2705 Pipeline Model Audit Passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Pipeline Blocked: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}